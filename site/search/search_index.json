{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-omnibenchmark-documentation","title":"Welcome to Omnibenchmark documentation","text":"<p>Omnibenchmark is a benchmark project that aims to provide community-driven, modular, extensible and always up-to-date benchmarks.</p> <p>It is based on the Renku project, an open and collaborative data analysis platform.</p> <p>The framework connects data, methods and metrics repositories (a.k.a. modules), that can be flexibly extended by any community member.</p> <p>If you are interested in contributing a new method, dataset or metric, follow the documentation from the <code>Getting started</code> section, where you can learn more about how omnibenchmark works and how to extend it with a new module.</p> <p>If you are interested in exploring one of the existing benchmarks and the latest results, you can directly jump to the results of our evaluations in the <code>Output</code> section.</p> <p></p>"},{"location":"01_landing/","title":"Motivation","text":"<p>Benchmarking is a critical step for the development of bioinformatic methods and provides important insights for their application.</p> <p>The current benchmarking scheme has many limitations:</p> <ul> <li> <p>It is a snapshot of the available methods at a certain time point and often already outdated when published.</p> </li> <li> <p>Comparison of benchmarks is challenging: different procedures, different datasets, different evaluation criteria, etc.</p> </li> <li> <p>All of the above can lead to different conclusions among benchmarks made at different time points or at different groups.</p> </li> </ul>"},{"location":"01_landing/#concept","title":"Concept","text":"<p>Omnibenchmark is a modular and extensible framework based on a free open-source analytic platform, Renku, to offer a continuous and open community benchmarking system.</p> <p>The framework consists of data, method and metric repositories (or \u201cmodules\u201d) that share data components and are tracked via a knowledge graph from the Renku system. The results can be displayed in an interactive dashboard to be openly explored by anyone looking for recommendations of tools. New data, methods or metrics can be added by the community to extend the benchmark.</p> <p>Some key features of our benchmarking framework:</p> <ul> <li> <p>Periodical updates of the benchmark to provide up-to-date results</p> </li> <li> <p>Easy extensibility through templates for data, methods or metrics</p> </li> <li> <p>Following FAIR principles by using software containers, an integration with Gitlab and full provenance tracking (inputs, workflows and generated files)</p> </li> <li> <p>Flexibility to work with different benchmarking structures, topics and programming languages.</p> </li> </ul>"},{"location":"01_landing/#prototype","title":"Prototype","text":"<p>We are currently building a prototype for community-based benchmarking of single cell batch correction methods. The research in single-cell is a perfect use-case, where more than 1000 tools have been developed in only a few years (see  for e.g. scrna-tools)  and where the benchmarking efforts are often not coordinated , not extendable and not reproducible.</p>"},{"location":"about/","title":"Indetonsusque loca est epulas","text":""},{"location":"about/#calidi-seu","title":"Calidi seu","text":"<p>Lorem markdownum, nunc aret fragorem sorori, dea antemnas sinat, Philippi, auctor, adfixa! Aere Venulus, me dubitare fronte peregrina feruntur et iussit resolvite? Nocte cervix truncos recessit, apri his fatemur timori Tantalis, et haec metum clipeum.</p>"},{"location":"about/#non-nec-comitatur-palmae-redolentia-tamen-aut","title":"Non nec comitatur palmae redolentia tamen aut","text":"<p>Queri voce oblivia subito, ex timentes utque: ferox diligitur candidus veros. Vixque nostri nec est inpulsos cupiuntque in color, terris mihi oves gloria comae aut Salmaci? Inde causa tantos toro: non imo ab atque; abstrahit intexere. Saxum de totaque certe fecit nive triplici, si nam cum meo feroci diu culpa canibusve magna.</p>"},{"location":"about/#sine-fatemur-versa-perdite-est-isto-trabes","title":"Sine fatemur versa perdite est isto trabes","text":"<p>Facundia dixit huic nefasque decimo suae dixit non. Rectum dumque acies qua, dixerat, fitque, tali tuum bellica!</p> <p>Belua poenaededidit lecti ferunt fatale mutentur sacerdos alta, ab nec dis. Nam et Dianae vitare Numam, esse cum! Qui et Lycaon omnes: dixi oblita?</p>"},{"location":"about/#olorinis-summum","title":"Olorinis summum","text":"<p>Colunt breviter Saturnia Threicius motasse aestus tibi obliquo maesto caeruleaeque alti, qui cum vias tenet pelagi noctem? Uni axe ossa, laesi, sed ducere tantum caducas atricolor vicinia pervia!</p> <ol> <li>Veteris abit iussae ictus cohaesit</li> <li>Alter diro Scyllae suoque superat nullos Cumarum</li> <li>Plangoris prohibebant deferre capillis</li> <li>Ponit ante nemus</li> <li>Ait parte quem Hymenaeus</li> </ol> <p>Referrem per mihi spiritus, praecipites Somni quoque, oppositoque. Cum occuluit Iovem ire: pulcherrime neque frondes vultumque anili, sic habet sustulerat quam ad nymphae Haemonias ostendit! Lapis quaerens potitur carpitur iam, terra ima Autolycus Aegaeo, Tegeaea et! Etiam nitidum transire Bromiumque vestrum; thalami enim lateri profundum aconita nec!</p>"},{"location":"01_getting_started/","title":"Index","text":""},{"location":"01_getting_started/#getting-started","title":"Getting started","text":"<p>Depending on your role, navigate to the corresponding section </p> <ul> <li> <p>Module contributor: you would like to submit a new dataset, method or metric ? The next section will explain you how to create and submit a new module to an Omnibenchmark. </p> </li> <li> <p>Benchmarker: you have the design for a new benchmark that you would like to port on Omnibenchmark ? The second section will show you how to configure and populate a benchmark on our system. </p> </li> <li> <p>Method user: you would like to access the lattest results of an Omnibenchmark ? The third section will redirect you to shiny apps that will allow you to explore our benchmarks. </p> </li> </ul>"},{"location":"01_getting_started/01_module_contr/","title":"Index","text":""},{"location":"01_getting_started/01_module_contr/#getting-started","title":"Getting started","text":"<p>The main advantage of the Omnibenchmark project is its modularity: components can be easily added to the data, methods or metrics modules. </p> <p>The following sections will explain how to bring such extensions. If you are interested in adding modules to omnibenchmark, it is required that:</p> <ol> <li> <p>you have a valid account to access <code>Renku &lt;https://renkulab.io/&gt;</code>_ </p> </li> <li> <p>you have a script for you data, method or metric.</p> </li> </ol> <p>.. toctree::    :glob:    :maxdepth: 2    :includehidden:</p> <p>start/*</p>"},{"location":"01_getting_started/01_module_contr/config_yaml/","title":"Config.yaml file","text":"<p>(section-config)=</p>"},{"location":"01_getting_started/01_module_contr/config_yaml/#the-configyaml-file","title":"The config.yaml file","text":"<p>Usually all specific information about a benchmark project can be specified in a <code>config.yaml</code> file. Below we show an example with all standard fields and explanations to them. Many fields are optional and do not apply to all modules. All unneccessary fields can be skipped. There are further optional fields for specfic edge cases, that are described in an extra <code>config.yaml</code> file. In general the <code>config.yaml</code> file consists of a data, an input, an output and a parameter section as well as a few extra fields to define the main benchmark script and benchmark type. Except for the data section the other sections are optional. Multiple values can be parsed as lists.</p> <pre><code># Data section to describe the object and the associated (result) dataset\ndata:\n    # Name of the dataset\n    name: \"out_dataset\"\n    # Title of the dataset (Optional)\n    title: \"Output of an example OmniObject\"\n    # Description of the dataset (Optional)\n    description: \"This dataset is supposed to store the output files from the example omniobject\"\n    # Dataset keyword(s) to make this dataset reachable for other projects/benhcmark components\n    keywords: [\"example_dataset\"]\n# Script to be run by the workflow associated to the project\nscript: \"path/to/method/dataset/metric/script.py\"\n# Interpreter to run the script (Optional, automatic detection)\ninterpreter: \"python\"\n# Benchmark that the object is associated to.\nbenchmark_name: \"omni_celltype\"\n# Orchestrator url of the benchmark (Optional, automatic detection)\norchestrator: \"https://www.orchestrator_url.com\"\n# Input section to describe output file types. (Optional)\ninputs:\n    # Keyword to find input datasets, that shall be imported \n    keywords: [\"import_this\", \"import_that\"]\n    # Input file types\n    files: [\"count_file\", \"dim_red_file\"]\n    # Prefix (part of the filename is sufficient) to automatically detect file types by their names\n    prefix:\n        count_file: \"counts\"\n        dim_red_file: [\"features\", \"genes\"]\n# Output section to describe output file types. (Optional)\noutputs:\n    # Output filetypes and their endings\n    files:\n        corrected_counts: \n            end: \".mtx.gz\"\n        meta:\n            end: \".json\"\n# Parameter section to describe the parameter dataset, values and filter. (Optional)\nparameter:\n    # Names of the parameter to use\n    names: [\"param1\", \"param2\"]\n    # Keyword(s) used to import the parameter dataset\n    keywords: [\"param_dataset\"]\n    # Filter that specify limits, values or combinations to exclude\n    filter:\n        param1:\n            upper: 50\n            lower: 3\n            exclude: 12\n    param2:\n        \"path/to/file/with/parameter/combinations/to/exclude.json\"\n</code></pre> <p>Specific fields, that are only relevant for edge cases. These fields have their counterparts in the generated {ref}<code>OmniObject &lt;section-classes&gt;</code>. Changes of the attributes of the OmniObject instance have the same effects, but come with the flexibility of python code. </p> <pre><code># Command to generate the workflow with (Optional, automatic detection)\ncommand_line: \"python path/to/method/dataset/metric/script.py --count_file data/import_this_dataset/...mtx.gz\"\ninputs:\n    # Datasets and manual file type specifications (automatic detection!)\n    input_files:\n        import_this_dataset:\n            count_file: \"data/import_this_dataset/import_this_dataset__counts.mtx.gz\"\n            dim_red_file: \"data/import_this_dataset/import_this_dataset__dim_red_file.json\"\n    # (Dataset) name that default input files belong to (Optional, automatic detection)\n    default: \"import_this_dataset\"\n    # Input dataset names that should be ignored (even if they have one of the specified input keywords assciated)\n    filter_names: [\"data1\", \"data2\"]\noutputs:\n    # Template to automatically generate output filenames (Optional - recommended for advanced user only)\n    template: \"data/${name}/${name}_${unique_values}_${out_name}.${out_end}\"\n    # Variables used for automatic output filename generation (Optional - recommended for advanced user only)\n    template_vars:\n        vars1: \"random\"\n        vars2: \"variable\"\n    # Manual specification of mapping for output files and their corresponding input files and parameter values (automatic detection!)\n    file_mapping:\n        mapping1: \n            output_files:\n                corrected_counts: \"data/out_dataset/out_dataset_import_this__param1_10__param2_test_corrected_counts.mtx.gz\"\n                meta: \"data/out_dataset/out_dataset_import_this__param1_10__param2_test_meta.json\"\n        input_files:\n            count_file: \"data/import_this_dataset/import_this_dataset__counts.mtx.gz\"\n            dim_red_file: \"data/import_this_dataset/import_this_dataset__dim_red_file.json\"\n        parameter:\n            param1: 10\n            param2: \"test\"\n    # Default output files (Optional, automatic detection)\n    default:\n        corrected_counts: \"data/out_dataset/out_dataset_import_this__param1_10__param2_test_corrected_counts.mtx.gz\"\n        meta: \"data/out_dataset/out_dataset_import_this__param1_10__param2_test_meta.json\"\nparameter:\n    default:\n        param1: 10\n        param2: \"test\"\n</code></pre>"},{"location":"01_getting_started/01_module_contr/project_setup/","title":"Project setup","text":"<p>(section-start-project)=</p>"},{"location":"01_getting_started/01_module_contr/project_setup/#start-a-renku-project","title":"Start a renku project","text":"<p>Each module of omnibenchmark is an independent renku project. It can be setup as a new GitLab project with the following features:</p> <ul> <li>A <code>Dockerfile</code> to specify the computational environment to run your project in.</li> <li>A <code>gitlab-ci.yaml</code> file to continuously build and update the projects Docker container and module script.</li> <li><code>Git LFS</code> for large file storage.</li> <li>Further project organisation files like a <code>.gitignore</code>, <code>.gitattributes</code>, <code>.renkulfsignore</code>, <code>.dockerignore</code>.</li> </ul> <p>Having independent modules also means that you can test your code and work on your project without being included into an existing benchmark. Only when a project is included into an omnibenchmark orchestrator it becomes part of the benchmark itself (explained latter Omnibenchmark modules) .</p> <p>To start a new renku project login at the renku with your GitHub account, OrchID or SWITCH-eduID or register a renku account. :::info Start a new renku project: renkulab.io -&gt; projects -&gt; + New project ::: Select a name, namespace, description and suitable template and create a new project. There are no specific requirements for omnibenchmark at this stage.</p> <p>Read more about renku projects here.</p>"},{"location":"01_getting_started/01_module_contr/project_setup/#specify-your-modules-environment","title":"Specify your modules environment","text":"<p>A module environment can be specified by modifying the <code>Dockerfile</code>. To run omnibenchmark you need the python modules renku-python and omnibenchmark installed. There are no further requirements, but it can be useful to follow the template structure in the automatically generated <code>Dockerfile</code>. Depending on what template you chose a renku base image will be selected at the top. Make sure this base image is reasonable for your module (e.g. choose one with R installed if your module calls R code). Extra linux (ubuntu) software requirements can be specified within the <code>Dockerfile</code>, while python modules are typically defined in the <code>requirements.txt</code> file or using conda\u2019s environment management system in the <code>environment.yaml</code> file and installation of R packages is specified in the <code>install.R</code> file. Detailed instruction can be found here. The automatically generated <code>Dockerfile</code> already contains commands to install renku-python at the bottom, but you need to specify omnibenchmark with the version you want to use as software requirement:</p> <p>:::info Add this line to requirements.txt: omnibenchmark==VERSION :::</p> <p>If you want to call  R code and you chose a R template when creating the renku project the <code>install.R</code> file is automatically generated upon project creation. Otherwise make sure you switch to a <code>base image</code> with R installed and add the <code>install.R</code> file manually, as well as the following lines to your <code>Dockerfile</code>:</p> <pre><code># install the R dependencies\nCOPY install.R /tmp/\nRUN R -f /tmp/install.R\n</code></pre>"},{"location":"01_getting_started/01_module_contr/project_setup/#run-your-code","title":"Run your code","text":"<p>After each commit renku builds automatically a Docker container with your specified requirements. You can start an interactive session using the latest container at renkulab.io or work with renku on your own machine.</p>"},{"location":"01_getting_started/01_module_contr/templates/","title":"Start from templates","text":""},{"location":"01_getting_started/01_module_contr/templates/#templates","title":"Templates","text":"<p>Any part of Omnibenchmark can be extended with an additional project that will add a new dataset, method or metric to the evaluation. </p> <p>To ease the addition of a new project to Omnibenchmark, you can select a template when creating a new Renku project. </p> <p>.. note::     Omnibenchmark is built upon the Renku system but the templates are made in a way that you won't have to worry about the underlying Renku mechanisms! You will just have to add your data and/or your code to project that will extend Omnibenchmark. </p> <p>.. _section-template:</p>"},{"location":"01_getting_started/01_module_contr/templates/#using-templates-on-renku","title":"Using templates on Renku","text":"<p>The following steps will show you how to create a new Omnibenchmark project for any step (data, method, metric,...).</p> <ol> <li>On <code>Renku &lt;https://renkulab.io/&gt;</code>_ start a new project by clicking the \"+\" symbol and add a tittle and a description to your project (this will appear under your project title in your list of projects). </li> </ol> <p>.. image:: ../_static/images/datatemplate0.png</p> <ol> <li> <p>On the \"New project\" page, fill in the required information. Under \"Repository URL\", indicate https://github.com/ansonrel/contributed-project-templates</p> </li> <li> <p>Under \"Repository Reference\", indicate \"main\".</p> </li> <li> <p>Fetch the templates. </p> </li> </ol> <p>.. image:: ../_static/images/datatemplate1.png</p> <ol> <li> <p>Once completed, select the desired omnibenchmark template (here as example, the \"Basic omnibenchmark dataset\" template to add a new dataset) and add all metadata that are required (you will be able to modify them latter if needed).</p> </li> <li> <p>Create your project.</p> </li> </ol> <p>.. image:: ../_static/images/datatemplate2.png</p> <ol> <li>The template will generate a new project will all the required tools for you to extend omnibenchmark. You will find further instructions in the dedicated <code>Module documentation &lt;https://omnibenchmark.readthedocs.io/en/latest/start/02_omnibenchmark_modules.html&gt;</code>_ , which will depend on the template that you selected. </li> </ol>"},{"location":"01_getting_started/01_module_contr/modules/","title":"Index","text":""},{"location":"01_getting_started/01_module_contr/modules/#omnibenchmark-modules","title":"Omnibenchmark modules","text":"<p>Omnibenchmark uses the Renku platform to run open and continuous benchmarks.  To contribute an independent module to one of the existing benchmarks start by creating a <code>new renku project &lt;https://omnibenchmark.readthedocs.io/en/latest/start/01_project_setup.html#start-a-renku-project&gt;</code>.  Each module consists of a Docker image, that defines its environment, a dataset to store outputs and metadata, a workflow that describes how to generate outputs and input and parameter datasets with input files and parameter definitions, if they are used.  Thus each module is an independent benchmark part and can be run, used and modified independently as such.  Modules are connected by importing (result) datasets from other modules as input datasets and will automatically be updated according to them. All relevant information on how to run a specific module are stored as <code>OmniObject &lt;https://omnibenchmark.readthedocs.io/en/latest/topic_guides/classes/01_omni_object.html&gt;</code>. The most convenient way to generate an instance of an OmniObject is to build it from a <code>config.yaml &lt;https://omnibenchmark.readthedocs.io/en/latest/topic_guides/02_config_yaml.html&gt;</code>_ file `. This structure is universal all modules can be build upon it.  In the following we describe example setups for different benchmark stages (dataset modules, methods modules, metrics modules).  Depending on the benchmark these can be flexibly extended and adapted to the benchmark structure. <p>.. toctree::    :glob:    :maxdepth: 1    :includehidden:</p> <p>modules/*</p>"},{"location":"01_getting_started/01_module_contr/modules/01_data/","title":"Data modules","text":"<p>Data modules are modules that define input datasets and bundle them into a renku dataset, that can be imported by other projects. Benchmark specific requirements like file formats, types and prefixes can be checked at the omnibenchmark webside. Most modules contain 3 main files:</p>"},{"location":"01_getting_started/01_module_contr/modules/01_data/#1-the-configyaml-file","title":"1. The config.yaml file","text":"<p>All information about the module are specified in the {ref}<code>config.yaml file &lt;section-config&gt;</code>:</p> <pre><code>---\ndata:\n    name: \"dataset-name\"\n    title: \"dataset title\"\n    description: \"A new dataset module for omnibenchmark\"\n    keywords: [\"MODULE_KEY\"]\nscript: \"path/to/module_script\"\noutputs:\n    files:\n        data_file1: \n            end: \"FILE1_END\"\n        data_file2:\n            end: \"FILE2_END\"\n        data_file3:\n            end: \"FILE3_END\"\nbenchmark_name: \"OMNIBENCHMARK_TYPE\"\n</code></pre> <p>Entries in capital letters depend on the specifications at the omnibenchmark webside.</p>"},{"location":"01_getting_started/01_module_contr/modules/01_data/#2-the-run_workflowpy-file","title":"2. The run_workflow.py file","text":"<p>This file is to generate, run and update the modules dataset and workflow. A most basic script to do so looks like this:</p> <pre><code># Load modules\nfrom omnibenchmark.utils.build_omni_object import get_omni_object_from_yaml\nfrom omnibenchmark.renku_commands.general import renku_save\n\n# Build an OmniObject from the config.yaml file\nomni_obj = get_omni_object_from_yaml('src/config.yaml')\n\n# Create the output dataset\nomni_obj.create_dataset()\nrenku_save()\n\n## Run and update the workflow\nomni_obj.run_renku()\nrenku_save()\n\n## Add files to output dataset\nomni_obj.update_result_dataset()\nrenku_save()\n</code></pre>"},{"location":"01_getting_started/01_module_contr/modules/01_data/#3-the-module-script","title":"3. The module script","text":"<p>This is the script to load the dataset and to convert its files into the expected format. Omnibenchmark accepts any kind of script and its maintenance and content is up to the module author. Omnibenchmark calls this script from the command line. If you use another language than R, Python, Julia or bash, specify the interpreter to use in the corresponding field of the {ref}<code>config.yaml file &lt;section-config&gt;</code> file.</p> <p>:::note All input and output files and if applicable parameter need to be parsed from the command line in the format: <code>--ARGUMENT_NAME ARGUMENT_VALUE</code> :::</p> <p>In Python argparse can be used to parse command arguments like this:</p> <pre><code># Load module\nimport argparse\n\n# Get command line arguments and store them in args\nparser=argparse.ArgumentParser()\nparser.add_argument('--argument_name', help='Description of the argument')\nargs=parser.parse_args()\n\n# Call the argument\narg1 = args.argument_name\n\n</code></pre> <p>In R we recommend to use the optparse package:</p> <pre><code># Load package\nlibrary(optparse)\n\n# Get list with command line arguments by name\noption_list = list(\n    make_option(c(\"--argument_name\"), type=\"character\", default=NULL, \n              help=\"Description of the argument\", metavar=\"character\")\n); \n\nopt_parser = OptionParser(option_list=option_list);\nopt = parse_args(opt_parser);\n\n# An useful error if the argument is missing\nif (is.null(opt$argument_name)){\n  print_help(opt_parser)\n  stop(\"Argument_name needs to be specified, but is missing.n\", call.=FALSE)\n}\n\n# Call the argument\narg1 &lt;- opt$argument_name\n</code></pre>"},{"location":"01_getting_started/01_module_contr/modules/02_method/","title":"Method modules","text":"<p>A method module imports all datasets of a benchmark or all preprocessed inputs and runs one benchmarking method on them. Method outputs are added to a renku dataset, that can be imported by metric projects to evaluate them. Benchmark specific requirements like file formats, types and prefixes can be checked at the omnibenchmark webside. To exlore a methods parameter space a parameter dataset is imported. Valid parameter can be specified in the <code>config.yaml file &lt;section-config&gt;</code> or specific {ref}<code>filter &lt;section-filter&gt;</code> files. There are {ref}<code>filter &lt;section-filter&gt;</code> at different level, e.g. parameter limits, specific values and parameter and input file combinations. Usually a method module contains only one workflow, that is automatically run with all valid parameter and input file combinations. Most modules contain 3 main files:</p>"},{"location":"01_getting_started/01_module_contr/modules/02_method/#1-the-configyaml-file","title":"1. The config.yaml file","text":"<p>All information about the module are specified in the {ref}<code>config.yaml file &lt;section-config&gt;</code>:</p> <pre><code>---\ndata:\n    name: \"method name\"\n    title: \"method title\"\n    description: \"Short description of the method\"\n    keywords: [\"MODULE_KEY\"]\nscript: \"path/to/module_script\"\nbenchmark_name: \"OMNIBENCHMARK_TYPE\"\ninputs:\n    keywords: [\"INPUT_KEY1\", \"INPUT_KEY2\"]\n    files: [\"input_file_name1\", \"input_file_name2\"]\n    prefix:\n        input_file_name1: \"_INPUT1_\"\n        input_file_name2: \"_INPUT2_\"\noutputs:\n    files:\n        method_result1: \n            end: \"FILE1_END\"\n        method_result2:\n            end: \"FILE2_END\"\nparameter:\n    names: [\"parameter1\", \"parameter2\"]\n    keywords: [\"PARAMETER_KEY\"]\n</code></pre> <p>Entries in capital letters depend on the specifications at the omnibenchmark webside.</p>"},{"location":"01_getting_started/01_module_contr/modules/02_method/#2-the-run_workflowpy-file","title":"2. The run_workflow.py file","text":"<p>This file is to generate, run and update the modules dataset and workflow. A most basic script to do so looks like this:</p> <pre><code># Load modules\nfrom omnibenchmark.utils.build_omni_object import get_omni_object_from_yaml\nfrom omnibenchmark.renku_commands.general import renku_save\n\n# Build an OmniObject from the config.yaml file\nomni_obj = get_omni_object_from_yaml('src/config.yaml')\n\n# Import and update inputs/parameter and update object accordingly \nomni_obj.update_object()\nrenku_save()\n\n# Create the output dataset\nomni_obj.create_dataset()\nrenku_save()\n\n## Run and update the workflow on all inputs and parameter combinations\nomni_obj.run_renku()\nrenku_save()\n\n## Add files to output dataset\nomni_obj.update_result_dataset()\nrenku_save()\n</code></pre>"},{"location":"01_getting_started/01_module_contr/modules/02_method/#3-the-module-script","title":"3. The module script","text":"<p>This is the script to load the dataset and to convert its files into the expected format. Omnibenchmark accepts any kind of script and its maintenance and content is up to the module author. Omnibenchmark calls this script from the command line. If you use another language than R, Python, Julia or bash, specify the interpreter to use in the corresponding field of the {ref}<code>config.yaml file &lt;section-config&gt;</code> file.</p> <p>:::note All input and output files and if applicable parameter need to be parsed from the command line in the format: <code>--ARGUMENT_NAME ARGUMENT_VALUE</code> :::</p> <p>In Python argparse can be used to parse command arguments like this:</p> <pre><code># Load module\nimport argparse\n\n# Get command line arguments and store them in args\nparser=argparse.ArgumentParser()\nparser.add_argument('--argument_name', help='Description of the argument')\nargs=parser.parse_args()\n\n# Call the argument\narg1 = args.argument_name\n\n</code></pre> <p>In R we recommend to use the optparse package:</p> <pre><code># Load package\nlibrary(optparse)\n\n# Get list with command line arguments by name\noption_list = list(\n    make_option(c(\"--argument_name\"), type=\"character\", default=NULL, \n              help=\"Description of the argument\", metavar=\"character\")\n); \n\nopt_parser = OptionParser(option_list=option_list);\nopt = parse_args(opt_parser);\n\n# An useful error if the argument is missing\nif (is.null(opt$argument_name)){\n  print_help(opt_parser)\n  stop(\"Argument_name needs to be specified, but is missing.n\", call.=FALSE)\n}\n\n# Call the argument\narg1 &lt;- opt$argument_name\n</code></pre>"},{"location":"01_getting_started/01_module_contr/modules/03_metric/","title":"Metric modules","text":"<p>A metric module imports method result datasets and runs one evaluation on them. Evaluation results are added to a renku dataset, that can be summarized and explored in an {ref}<code>omnibenchmark bettr dashboard &lt;section-output&gt;</code>. Benchmark specific requirements like file formats, types and prefixes can be checked at the omnibenchmark webside. Usually a metric module contains two workflows, one to evaluate the results and one to generate the <code>metric info file</code>. Most metric modules contain 5 main files:</p>"},{"location":"01_getting_started/01_module_contr/modules/03_metric/#1-the-configyaml-file","title":"1. The config.yaml file","text":"<p>All information about the module are specified in the {ref}<code>config.yaml file &lt;section-config&gt;</code>:</p> <pre><code>---\ndata:\n    name: \"metric name\"\n    title: \"metric title\"\n    description: \"Short description of the metric\"\n    keywords: [\"MODULE_KEY\"]\nscript: \"path/to/module_script\"\nbenchmark_name: \"OMNIBENCHMARK_TYPE\"\ninputs:\n    keywords: [\"INPUT_KEY1\", \"INPUT_KEY2\"]\n    files: [\"input_file_name1\", \"input_file_name2\"]\n    prefix:\n        input_file_name1: \"_INPUT1_\"\n        input_file_name2: \"_INPUT2_\"\noutputs:\n    files:\n        metric_result: \n            end: \"FILE1_END\"\n</code></pre> <p>Entries in capital letters depend on the specifications at the omnibenchmark webside.</p>"},{"location":"01_getting_started/01_module_contr/modules/03_metric/#2-the-info_configyaml-file","title":"2. The info_config.yaml file","text":"<p>All information about the module are specified in the {ref}<code>config.yaml file &lt;section-config&gt;</code>:</p> <pre><code>---\ndata:\n    name: \"metric name\"\nscript: \"src/generate_metric_info.py\"\nbenchmark_name: \"OMNIBENCHMARK_TYPE\"\noutputs:\n    files:\n        metric_info: \n            end: \"json\"\n    file_mapping:\n        mapping1:\n          output_files:\n            metric_info: \"path/to/metric_name_info.json\"\n</code></pre>"},{"location":"01_getting_started/01_module_contr/modules/03_metric/#3-the-run_workflowpy-file","title":"3. The run_workflow.py file","text":"<p>This file is to generate, run and update the modules dataset and workflow. A most basic script to do so looks like this:</p> <pre><code># Load modules\nfrom omnibenchmark.utils.build_omni_object import get_omni_object_from_yaml\nfrom omnibenchmark.renku_commands.general import renku_save\n\n# Build an OmniObject from the config.yaml file\nomni_obj = get_omni_object_from_yaml('src/config.yaml')\n\n# Import and update inputs/parameter and update object accordingly \nomni_obj.update_object()\nrenku_save()\n\n# Create the output dataset\nomni_obj.create_dataset()\nrenku_save()\n\n## Run and update the workflow on all inputs and parameter combinations\nomni_obj.run_renku()\nrenku_save()\n\n## Add files to output dataset\nomni_obj.update_result_dataset()\nrenku_save()\n\n###################### Generate info file ######################\n# Build an OmniObject from the info_config.yaml file\nomni_info = get_omni_object_from_yaml('src/info_config.yaml')\nomni_info.wflow_name = \"metric_info\"\n\n## Run and update workflow\nomni_info.run_renku()\nrenku_save()\n\n## Update output dataset \nomni_info.update_result_dataset()\nrenku_save()\n</code></pre>"},{"location":"01_getting_started/01_module_contr/modules/03_metric/#4-the-module-script","title":"4. The module script","text":"<p>This is the script to load the dataset and to convert its files into the expected format. Omnibenchmark accepts any kind of script and its maintenance and content is up to the module author. Omnibenchmark calls this script from the command line. If you use another language than R, Python, Julia or bash, specify the interpreter to use in the corresponding field of the {ref}<code>config.yaml file &lt;section-config&gt;</code> file.</p> <p>:::note All input and output files and if applicable parameter need to be parsed from the command line in the format: <code>--ARGUMENT_NAME ARGUMENT_VALUE</code> :::</p> <p>In Python argparse can be used to parse command arguments like this:</p> <pre><code># Load module\nimport argparse\n\n# Get command line arguments and store them in args\nparser=argparse.ArgumentParser()\nparser.add_argument('--argument_name', help='Description of the argument')\nargs=parser.parse_args()\n\n# Call the argument\narg1 = args.argument_name\n\n</code></pre> <p>In R we recommend to use the optparse package:</p> <pre><code># Load package\nlibrary(optparse)\n\n# Get list with command line arguments by name\noption_list = list(\n    make_option(c(\"--argument_name\"), type=\"character\", default=NULL, \n              help=\"Description of the argument\", metavar=\"character\")\n); \n\nopt_parser = OptionParser(option_list=option_list);\nopt = parse_args(opt_parser);\n\n# An useful error if the argument is missing\nif (is.null(opt$argument_name)){\n  print_help(opt_parser)\n  stop(\"Argument_name needs to be specified, but is missing.n\", call.=FALSE)\n}\n\n# Call the argument\narg1 &lt;- opt$argument_name\n</code></pre>"},{"location":"01_getting_started/01_module_contr/modules/03_metric/#5-the-generate_metric_infopy-file","title":"5. The generate_metric_info.py file","text":"<p>This file could also be written in R or any other language. It should return a json file with the below fields with the metrics information.</p> <pre><code>import argparse\nimport json\n\nparser=argparse.ArgumentParser()\nparser.add_argument('--metric_info', help='Path to the metric info json file')\nargs=parser.parse_args()\n\nmetric_info = {\n    'flip': False,\n    'max': 1,\n    'min': 0,\n    'group': \"METRIC_GROUP\",\n    'name': \"metric_name\",\n    'input': \"metric_input_type\"\n}\n\nwith open(args.metric_info, \"w\") as fp:\n    json.dump(metric_info , fp, indent=3) \n</code></pre>"},{"location":"01_getting_started/01_module_contr/modules/04_submit/","title":"Submit a module to an Omnibenchmark","text":"<p>An omnibenchmark module will be able to import datasets from other modules and export its output to others. However, it still needs to be integrated in an Omnibenchmark orchestrator. An orchestrator is an omnibenchmark project which orchestrates the deployment, running and testing of each pieces of an Omnibenchmark. </p>"},{"location":"01_getting_started/01_module_contr/modules/04_submit/#integrate-a-module-to-an-orchestrator","title":"Integrate a module to an orchestrator","text":"<p>The list of current Omnibenchmarks and their related orchestrator can be found on the Omnibenchmark dashboard: </p> <ul> <li> <p>Omni-batch orchestrator</p> </li> <li> <p>Omni-clustering orchestrator</p> </li> </ul> <p>To integrate your (populated and tested) module: </p> <ul> <li> <p>Follow the link to the relevant orchestrator</p> </li> <li> <p>Open a new issue and describe briefly the aim of your module (data/ method/ metric module ?)</p> </li> <li> <p>The development team will check your module and integrate it in the Orchestrator worfklow. When it is done, you will be able to view the result of your module on the shiny app. </p> </li> </ul>"},{"location":"01_getting_started/02_benchmarker/","title":"Index","text":""},{"location":"01_getting_started/02_benchmarker/#benchmarker","title":"Benchmarker","text":""},{"location":"01_getting_started/02_benchmarker/#project-setup-with-omnibus","title":"Project setup with Omnibus","text":""},{"location":"01_getting_started/02_benchmarker/#populating-the-benchmark","title":"Populating the benchmark","text":"<p>See <code>Module contributor</code></p>"},{"location":"01_getting_started/02_benchmarker/#setting-up-an-orchestrator","title":"Setting up an orchestrator","text":""},{"location":"01_getting_started/03_method_user/","title":"Benchmark outputs","text":"<p>Available here: http://omnibenchmark.org/p/results/</p>"},{"location":"02_advanced/","title":"Index","text":""},{"location":"02_advanced/#advanced-topics","title":"Advanced topics","text":"<ul> <li> <p>Module contributor: better control inputs, outputs and scripts. </p> </li> <li> <p>Benchmarker: more complex designs and better control how your benchmark is run and populated.</p> </li> <li> <p>Method user: download the results of a benchmark on your computer and wrangle the shiny app to your needs. </p> </li> </ul>"},{"location":"02_advanced/01_module_contr/","title":"Index","text":""},{"location":"02_advanced/01_module_contr/#advances-topics-for-module-contributor","title":"Advances topics for module contributor","text":"<ul> <li>The <code>omni_object</code> instance and its classes</li> </ul>"},{"location":"02_advanced/01_module_contr/omni_object/","title":"Omnibenchmark classes","text":"<p>This section describes classes to manage omnibenchmark modules and their interactions. The main class is the <code>OmniObject</code>, which consollidates all relevant information and functions of a module. This object has further subclasses that define inputs, outputs, commands and the workflow.</p>"},{"location":"02_advanced/01_module_contr/omni_object/classes/01_omni_object/","title":"OmniObject","text":"<p>Main class to manage an omnibenchmark module. It takes the following arguments:</p> <ul> <li><code>name (str)</code>: Module name</li> <li><code>keyword (Optional[List[str]], optional)</code>: Keyword associated to the modules output dataset.</li> <li><code>title (Optional[str], optional)</code>: Title of the modules output dataset.</li> <li><code>description (Optional[str], optional)</code>: Description of the modules output dataset.</li> <li><code>script (Optional[PathLike], optional)</code>: Script to generate the modules workflow for.</li> <li><code>command (Optional[OmniCommand], optional)</code>: Workflow command - will be automatically generated if missing.</li> <li><code>inputs (Optional[OmniInput], optional)</code>: Definitions of the workflow inputs.</li> <li><code>parameter (Optional[OmniParameter], optional)</code>: Definitions of the workflow parameter.</li> <li><code>outputs (Optional[OmniOutput], optional)</code>: Definitions of the workflow outputs.</li> <li><code>omni_plan (Optional[OmniPlan], optional)</code>: The workflow description.</li> <li><code>benchmark_name (Optional[str], optional)</code>: Name of the benchmark the module is associated to.</li> <li><code>orchestrator (Optional[str], optional)</code>: Orchestrator url of the benchmark th emodule is associated to. Automatic detection.</li> <li><code>wflow_name (Optional[str], optional)</code>: Workflow name. Will be set to the module name if none.</li> <li><code>dataset_name (Optional[str], optional)</code>: Dataset name. Will be set to the module name if none.</li> </ul> <p>The following class methods can be run on an instance of an OmniObject:</p> <ul> <li><code>create_dataset()</code>: Method to create a renku dataset with the in the object specified attributes in the current renku project.</li> <li><code>update_object()</code>: Method to check for new imports or updates in input and the parameter datasets. Will update object attributes accordingly.</li> <li><code>run_renku()</code>: Method to generate and update the workflow and all output files as specified in the object.</li> <li><code>update_result_dataset()</code>: Method to update and add all output datasets to the dataset specified in the object.</li> </ul>"},{"location":"02_advanced/01_module_contr/omni_object/classes/02_omni_input/","title":"OmniInput","text":"<p>Class to manage inputs of an omnibenchmark module. This class has the following attributes:</p> <ul> <li><code>names (List[str])</code>: Names of the input filetypes</li> <li><code>prefix (Optional[Mapping[str, List[str]]], optional)</code>: Prefixes (or substrings) of the input filetypes.</li> <li><code>input_files (Optional[Mapping[str, Mapping[str, str]]], optional)</code>: Input files ordered by file types.</li> <li><code>keyword (Optional[List[str]], optional)</code>: Keyword to define which datasets are imported as input datasets.</li> <li><code>default (Optional[str], optional)</code>: Default input name (e.g., dataset).</li> <li><code>filter_names (Optional[List[str]], optional)</code>: Input dataset names to be ignored.</li> </ul> <p>The following class methods can be run on an instance of an OmniInput:</p> <ul> <li><code>update_inputs()</code>: Method to import new and update existing input datasets and update the object accordingly</li> </ul>"},{"location":"02_advanced/01_module_contr/omni_object/classes/03_omni_parameter/","title":"OmniParameter","text":"<p>Class to manage parameter of an omnibenchmark module. This class has the following attributes:</p> <ul> <li><code>names (List[str])</code>: Name of all valid parameter</li> <li><code>values (Optional[Mapping[str, List]], optional)</code>: Parameter values - usually automatically detected.</li> <li><code>default (Optional[Mapping[str, str]], optional)</code>: Default parameter values.</li> <li><code>keyword (Optional[List[str]], optional)</code>: Keyword to import the parameter dataset with.</li> <li><code>filter (Optional[Mapping[str, str]], optional)</code>: Filter to use for the parameter space.</li> <li><code>combinations (Optional[List[Mapping[str, str]]], optional)</code>: All possible parameter combinations.</li> </ul> <p>The following class methods can be run on an instance of an OmniInput:</p> <ul> <li><code>update_parameter()</code>: Method to import and update parameter datasets and update the object/parameter space accordingly.</li> </ul>"},{"location":"02_advanced/01_module_contr/omni_object/classes/04_omni_output/","title":"OmniOutput","text":"<p>Class to manage outputs of an omnibenchmark module. This class has the following attributes:</p> <ul> <li><code>name (str)</code>: Name that is specific for all outputs. Typically the module name/OmniObject name.</li> <li><code>out_names (List[str])</code>: Names of the output file types</li> <li><code>output_end (Optional[Mapping[str, str]], optional)</code>: Endings of the output filetypes.</li> <li><code>out_template (str, optional)</code>: Template to generate output file names.</li> <li><code>file_mapping (Optional[List[OutMapping]], optional)</code>: Mapping of input files, parameter values and output files.</li> <li><code>inputs (Optional[OmniInput], optional)</code>: Object specifying all valid inputs.</li> <li><code>parameter (Optional[OmniParameter], optional)</code>: Object speccifying the parameter space.</li> <li><code>default (Optional[Mapping], optional)</code>: Default output files.</li> <li><code>filter_json(Optional[str], optional)</code>: Path to json file with filter combinations.</li> <li><code>template_fun (Optional[Callable[..., Mapping]], optional)</code>: Function to use to automatically generate output filenames.</li> <li><code>template_vars (Optional[Mapping], optional)</code>: Variables that are used by template_fun.</li> </ul> <p>The following class methods can be run on an instance of an OmniInput:</p> <ul> <li><code>update_outputs()</code>: Method to update the output definitions according to the objects attributes.</li> </ul>"},{"location":"02_advanced/01_module_contr/omni_object/classes/05_omni_command/","title":"OmniCommand","text":"<p>Class to manage the main workflow command of an omnibenchmark module. This class has the following attributes:</p> <ul> <li><code>script (Union[PathLike, str])</code>: Path to the script run by the command</li> <li><code>interpreter (str, optional)</code>: Interpreter to run the script with.</li> <li><code>command_line (str, optional)</code>: Command line to be run.</li> <li><code>outputs (OmniOutput, optional)</code>: Object specifying all outputs.</li> <li><code>input_val (Optional[Mapping], optional)</code>: Input file tyoes and paths to run the command on.</li> <li><code>parameter_val (Optional[Mapping], optional)</code>: Parameter names and values to run the command with.</li> </ul> <p>The following class methods can be run on an instance of an OmniInput:</p> <ul> <li><code>update_command()</code>: Method to update the command according to the outputs,inputs,parameter.</li> </ul>"},{"location":"02_advanced/01_module_contr/omni_object/classes/06_omni_plan/","title":"OmniPlan","text":"<p>Class to manage the workflow of an omnibenchmark module. This class has the following attributes:</p> <ul> <li><code>plan (PlanViewModel)</code>: A plan view model as defined in renku</li> <li><code>param_mapping (Optional[Mapping[str, str]], optional)</code>: A mapping between the component names of the plan and the OmniObject.</li> </ul> <p>The following class methods can be run on an instance of an OmniInput:</p> <ul> <li><code>predict_mapping_from_file_dict()</code>: Method to predict the mapping from the (input-, output-, parameter) file mapping used to generate the command.</li> </ul>"},{"location":"02_advanced/02_benchmarker/","title":"Advanced guides for benchmarker","text":""},{"location":"02_advanced/03_method_user/","title":"Index","text":""},{"location":"02_advanced/03_method_user/#advanced-topics-for-method-user","title":"Advanced topics for method user","text":""},{"location":"03_howto/","title":"Index","text":""},{"location":"03_howto/#how-tos","title":"How to's","text":""},{"location":"03_howto/#build-object","title":"Build object","text":""},{"location":"03_howto/#create-dataset","title":"Create dataset","text":""},{"location":"03_howto/#generate-workflow","title":"Generate workflow","text":""},{"location":"03_howto/#update-object","title":"Update object","text":""},{"location":"03_howto/#filter","title":"Filter","text":""},{"location":"03_howto/01_build_object/","title":"Build object","text":"<p>(section-build-yaml)=</p>"},{"location":"03_howto/01_build_object/#build-an-omniobject-from-yaml","title":"Build an OmniObject from yaml","text":"<p>All relevant information on how to run a specific module are stored as {ref}<code>OmniObject &lt;section-omniobject&gt;</code>. The most convenient way to generate an instance of an <code>OmniObject</code> is to build it from a <code>config.yaml</code> file using the <code>get_omni_object_from_yaml()</code> function:</p> <pre><code>## modules\nfrom omnibenchmark.utils.build_omni_object import get_omni_object_from_yaml\n\n## Load object\nomni_obj = get_omni_object_from_yaml('src/config.yaml')\n\n</code></pre>"},{"location":"03_howto/02_create_dataset/","title":"Create dataset","text":"<p>(section-datasets)=</p>"},{"location":"03_howto/02_create_dataset/#datasets","title":"Datasets","text":""},{"location":"03_howto/02_create_dataset/#generate-datasets","title":"Generate Datasets","text":""},{"location":"03_howto/02_create_dataset/#add-files","title":"Add files","text":""},{"location":"03_howto/02_create_dataset/#update-datasets","title":"Update datasets","text":""},{"location":"03_howto/03_generate_workflow/","title":"Generate workflow","text":"<p>(section-workflow)=</p>"},{"location":"03_howto/03_generate_workflow/#generate-and-update-workflows","title":"Generate and update workflows","text":""},{"location":"03_howto/04_update_object/","title":"Update object","text":"<p>(section-update)=</p>"},{"location":"03_howto/04_update_object/#update-omniobject","title":"Update OmniObject","text":""},{"location":"03_howto/05_filter/","title":"Filter","text":"<p>(section-filter)=</p>"},{"location":"03_howto/05_filter/#filter-omniobject","title":"Filter OmniObject","text":""},{"location":"03_howto/05_filter/#filter-input-datasets","title":"Filter input datasets","text":""},{"location":"03_howto/05_filter/#filter-parameter","title":"Filter parameter","text":""},{"location":"03_howto/05_filter/#parameter-limits","title":"Parameter limits","text":""},{"location":"03_howto/05_filter/#parameter-values","title":"Parameter values","text":""},{"location":"03_howto/05_filter/#parameter-combinations","title":"Parameter combinations","text":""},{"location":"03_howto/05_filter/#input-dataset-specific-parameter-combinations","title":"Input dataset specific parameter combinations","text":""},{"location":"04_bugs/","title":"Index","text":""},{"location":"04_bugs/#common-bugs","title":"Common bugs","text":"<p>List of common bugs and their solution. </p> <p>Put also contribution section. </p>"}]}